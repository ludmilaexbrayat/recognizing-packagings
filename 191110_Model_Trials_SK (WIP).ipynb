{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Appropriate Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Packages\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "# Torch Specific\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import models,transforms,datasets\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Project Specific\n",
    "\n",
    "sys.path.append(str(os.getcwd() + '/scripts'))\n",
    "from Preprocessing import MultiLabelDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Constants and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "IS_SHUFFLE = True\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Machine Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: False \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using gpu: %s ' % torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the tupple of tensors from the pickle file\n",
    "with open('data/train_data.pickle', 'rb') as handle:\n",
    "    train = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the data loader from the tupple of tensors\n",
    "train_loader = DataLoader(train,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=IS_SHUFFLE,\n",
    "                          num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pretrained VGG model\n",
    "model_vgg = models.vgg16(pretrained=True)\n",
    "\n",
    "# Freezing all layers\n",
    "for param in model_vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Adding linear layer\n",
    "model_vgg.classifier._modules['6'] = torch.nn.Linear(4096, 13)\n",
    "model_vgg.classifier._modules['7'] = torch.nn.Sigmoid()\n",
    "\n",
    "# Defining the optimizer\n",
    "optimizer_vgg = torch.optim.SGD(model_vgg.classifier[6].parameters(),lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, size, epochs=1, optimizer=None):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs,classes in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            classes = classes.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = torch.nn.BCELoss()\n",
    "            loss = loss(outputs, classes)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _,preds = torch.max(outputs.data,1)\n",
    "            # statistics\n",
    "            running_loss += loss.data.item()\n",
    "            running_corrects += torch.sum(preds == classes.data)\n",
    "        epoch_loss = running_loss / size\n",
    "        epoch_acc = running_corrects.data.item() / size\n",
    "        print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (16) must match the size of tensor b (13) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-53127710de7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             optimizer=optimizer_vgg)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-7a6b88a71365>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, size, epochs, optimizer)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_corrects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (16) must match the size of tensor b (13) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "train_model(model_vgg, \n",
    "            train_loader,\n",
    "            size=len(train),\n",
    "            epochs=2,\n",
    "            optimizer=optimizer_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([13])) that is different to the input size (torch.Size([1, 13])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `x >= 0. && x <= 1.' failed. input value should be between 0~1, but got -2.000000 at ../aten/src/THNN/generic/BCECriterion.c:60",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-0ccebf5844b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2065\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `x >= 0. && x <= 1.' failed. input value should be between 0~1, but got -2.000000 at ../aten/src/THNN/generic/BCECriterion.c:60"
     ]
    }
   ],
   "source": [
    "for image, classnames in train_loader:\n",
    "    target = torch.tensor([[0,1,0,-2,0,0,0,0,0,0,0,0,0]], dtype=torch.float32)\n",
    "    loss = torch.nn.BCELoss()\n",
    "    loss = loss(target, classnames[0])\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "for image, classnames in train_loader:\n",
    "    print(classnames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
